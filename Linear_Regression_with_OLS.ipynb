{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression using Ordinary Least Squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'E:\\1MS\\Projects\\LinearRegression_using_OLS'\n",
    "os.chdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_approximation_files(fname, N, M):\n",
    "    \"\"\" This function reads files \"\"\"\n",
    "    try:\n",
    "        with open(fname) as f:\n",
    "            data = []\n",
    "            for line in f:\n",
    "                data.extend(line.split())\n",
    "                \n",
    "    except IOError:\n",
    "        print(\"Cannot open file\")\n",
    "        sys.exit(1)\n",
    "        \n",
    "    data = [float(i) for i in data]\n",
    "    data = np.reshape(data, (len(data)//(N+M), (N+M)))\n",
    "    x = data[:, :N]\n",
    "    t = data[:, N:]\n",
    "    Nv = len(x)\n",
    "    \n",
    "    return x, t, Nv\n",
    "\n",
    "    \n",
    "class Standardize():\n",
    "    \"\"\" This class scales the data to have zero mean and unit variance \"\"\"\n",
    "    \n",
    "    def fit(self, x):\n",
    "        self.mean = x.mean(axis=0)\n",
    "        self.std = x.std(axis=0)\n",
    "        return \n",
    "        \n",
    "    \n",
    "    def transform(self, x):\n",
    "        x_t = x - self.mean\n",
    "        x_t = x_t / self.std\n",
    "        return x_t\n",
    "        \n",
    "        \n",
    "    def fit_transform(self, x):\n",
    "        self.fit(x)\n",
    "        x_t = self.transform(x)\n",
    "        return x_t\n",
    "\n",
    "\n",
    "def add_constant(x):\n",
    "    \"\"\" This functions adds the intercept/constant \"\"\"\n",
    "    \n",
    "    n = np.shape(x)[0]\n",
    "    xa = np.concatenate( (np.ones((n,1), dtype=float) , x),1)\n",
    "    return xa\n",
    "    \n",
    "    \n",
    "def get_preds(x, coef):\n",
    "    \"\"\" Returns the predicted values calculated from coefficients/ weights \"\"\"\n",
    "    \n",
    "    return np.dot(x, coef) \n",
    "\n",
    "\n",
    "def calc_error(y, y_pred, metric='mse'):\n",
    "    \"\"\" \n",
    "        Calculates the error between actual and predicted values.\n",
    "        Uses mean squared error metric by default. \n",
    "        By passing metric='sse', sum of squared error metric can be used\n",
    "    \"\"\"\n",
    "    \n",
    "    Nv_ = np.shape(y)[0]\n",
    "    loss = y - y_pred\n",
    "    \n",
    "    if metric == 'sse':\n",
    "        feature_error = sum(loss**2)/Nv_\n",
    "        try:\n",
    "            error = sum(feature_error)\n",
    "        except TypeError: # if there's only one dependent variable \n",
    "            error = feature_error\n",
    "    \n",
    "    elif metric == 'mse':\n",
    "        error = np.mean(loss**2)\n",
    "\n",
    "    return error\n",
    "\n",
    "\n",
    "#Helper functions    \n",
    "def get_source(lib):\n",
    "    ''' This function prints the source code of required library '''\n",
    "    \n",
    "    import inspect\n",
    "    print(inspect.getsource(lib))\n",
    "    \n",
    "    \n",
    "def gs(x, r=False):\n",
    "    \"\"\" gs: get shape - This function prints or returns the shape of given array \"\"\"\n",
    "    \n",
    "    if r:\n",
    "        return np.shape(x)\n",
    "    print(np.shape(x))\n",
    "    \n",
    "    \n",
    "def df(x):\n",
    "    \"\"\" df- returns input as a dataframe \"\"\"\n",
    "    \n",
    "    return pd.DataFrame(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = 'Twod.tra'\n",
    "N, M = 8, 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y, Nv = read_approximation_files(fname, N, M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1768, 8)\n",
      "(1768, 7)\n"
     ]
    }
   ],
   "source": [
    "gs(x)\n",
    "gs(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the data into training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.25, random_state=3, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1326, 8)\n",
      "(1326, 7)\n",
      "(442, 8)\n",
      "(442, 7)\n"
     ]
    }
   ],
   "source": [
    "gs(x_train)\n",
    "gs(y_train)\n",
    "gs(x_val)\n",
    "gs(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1326.000000</td>\n",
       "      <td>1326.000000</td>\n",
       "      <td>1326.000000</td>\n",
       "      <td>1326.000000</td>\n",
       "      <td>1326.000000</td>\n",
       "      <td>1326.000000</td>\n",
       "      <td>1326.000000</td>\n",
       "      <td>1326.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-15.689281</td>\n",
       "      <td>-15.857155</td>\n",
       "      <td>-19.715648</td>\n",
       "      <td>-20.965447</td>\n",
       "      <td>-22.497912</td>\n",
       "      <td>-25.395404</td>\n",
       "      <td>-25.437874</td>\n",
       "      <td>-31.304241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.450740</td>\n",
       "      <td>3.443045</td>\n",
       "      <td>2.648086</td>\n",
       "      <td>2.592289</td>\n",
       "      <td>2.584743</td>\n",
       "      <td>2.587408</td>\n",
       "      <td>2.954021</td>\n",
       "      <td>2.883025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-25.552600</td>\n",
       "      <td>-25.740200</td>\n",
       "      <td>-27.581900</td>\n",
       "      <td>-29.015100</td>\n",
       "      <td>-32.430900</td>\n",
       "      <td>-36.430800</td>\n",
       "      <td>-36.580900</td>\n",
       "      <td>-43.926500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-18.141025</td>\n",
       "      <td>-18.304900</td>\n",
       "      <td>-21.471450</td>\n",
       "      <td>-22.534475</td>\n",
       "      <td>-24.028050</td>\n",
       "      <td>-26.892475</td>\n",
       "      <td>-27.196575</td>\n",
       "      <td>-32.855050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-15.893100</td>\n",
       "      <td>-16.066350</td>\n",
       "      <td>-19.832300</td>\n",
       "      <td>-21.059650</td>\n",
       "      <td>-22.391650</td>\n",
       "      <td>-24.996050</td>\n",
       "      <td>-25.389650</td>\n",
       "      <td>-30.802000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-13.269175</td>\n",
       "      <td>-13.451600</td>\n",
       "      <td>-17.958750</td>\n",
       "      <td>-19.266625</td>\n",
       "      <td>-20.890000</td>\n",
       "      <td>-23.749375</td>\n",
       "      <td>-23.725775</td>\n",
       "      <td>-29.527925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>-6.571330</td>\n",
       "      <td>-6.752560</td>\n",
       "      <td>-12.558700</td>\n",
       "      <td>-13.987600</td>\n",
       "      <td>-15.527300</td>\n",
       "      <td>-19.037200</td>\n",
       "      <td>-17.206300</td>\n",
       "      <td>-24.222900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0            1            2            3            4  \\\n",
       "count  1326.000000  1326.000000  1326.000000  1326.000000  1326.000000   \n",
       "mean    -15.689281   -15.857155   -19.715648   -20.965447   -22.497912   \n",
       "std       3.450740     3.443045     2.648086     2.592289     2.584743   \n",
       "min     -25.552600   -25.740200   -27.581900   -29.015100   -32.430900   \n",
       "25%     -18.141025   -18.304900   -21.471450   -22.534475   -24.028050   \n",
       "50%     -15.893100   -16.066350   -19.832300   -21.059650   -22.391650   \n",
       "75%     -13.269175   -13.451600   -17.958750   -19.266625   -20.890000   \n",
       "max      -6.571330    -6.752560   -12.558700   -13.987600   -15.527300   \n",
       "\n",
       "                 5            6            7  \n",
       "count  1326.000000  1326.000000  1326.000000  \n",
       "mean    -25.395404   -25.437874   -31.304241  \n",
       "std       2.587408     2.954021     2.883025  \n",
       "min     -36.430800   -36.580900   -43.926500  \n",
       "25%     -26.892475   -27.196575   -32.855050  \n",
       "50%     -24.996050   -25.389650   -30.802000  \n",
       "75%     -23.749375   -23.725775   -29.527925  \n",
       "max     -19.037200   -17.206300   -24.222900  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df(x_train).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaling the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scale = Standardize()\n",
    "x_train_scaled = train_scale.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.326000e+03</td>\n",
       "      <td>1.326000e+03</td>\n",
       "      <td>1.326000e+03</td>\n",
       "      <td>1.326000e+03</td>\n",
       "      <td>1.326000e+03</td>\n",
       "      <td>1.326000e+03</td>\n",
       "      <td>1.326000e+03</td>\n",
       "      <td>1.326000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-1.035002e-14</td>\n",
       "      <td>-1.160124e-15</td>\n",
       "      <td>4.947274e-15</td>\n",
       "      <td>-9.380129e-15</td>\n",
       "      <td>1.081019e-14</td>\n",
       "      <td>6.446996e-15</td>\n",
       "      <td>2.151455e-15</td>\n",
       "      <td>-3.248616e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000377e+00</td>\n",
       "      <td>1.000377e+00</td>\n",
       "      <td>1.000377e+00</td>\n",
       "      <td>1.000377e+00</td>\n",
       "      <td>1.000377e+00</td>\n",
       "      <td>1.000377e+00</td>\n",
       "      <td>1.000377e+00</td>\n",
       "      <td>1.000377e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-2.859399e+00</td>\n",
       "      <td>-2.871520e+00</td>\n",
       "      <td>-2.971664e+00</td>\n",
       "      <td>-3.106401e+00</td>\n",
       "      <td>-3.844380e+00</td>\n",
       "      <td>-4.266647e+00</td>\n",
       "      <td>-3.773579e+00</td>\n",
       "      <td>-4.379782e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-7.107663e-01</td>\n",
       "      <td>-7.111927e-01</td>\n",
       "      <td>-6.632960e-01</td>\n",
       "      <td>-6.054958e-01</td>\n",
       "      <td>-5.922116e-01</td>\n",
       "      <td>-5.788168e-01</td>\n",
       "      <td>-5.955831e-01</td>\n",
       "      <td>-5.381132e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-5.908771e-02</td>\n",
       "      <td>-6.078163e-02</td>\n",
       "      <td>-4.406811e-02</td>\n",
       "      <td>-3.635347e-02</td>\n",
       "      <td>4.112692e-02</td>\n",
       "      <td>1.544036e-01</td>\n",
       "      <td>1.633087e-02</td>\n",
       "      <td>1.742722e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.015941e-01</td>\n",
       "      <td>6.989344e-01</td>\n",
       "      <td>6.637100e-01</td>\n",
       "      <td>6.555838e-01</td>\n",
       "      <td>6.223129e-01</td>\n",
       "      <td>6.364092e-01</td>\n",
       "      <td>5.798010e-01</td>\n",
       "      <td>6.163619e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.643315e+00</td>\n",
       "      <td>2.645342e+00</td>\n",
       "      <td>2.703707e+00</td>\n",
       "      <td>2.692786e+00</td>\n",
       "      <td>2.697847e+00</td>\n",
       "      <td>2.458291e+00</td>\n",
       "      <td>2.787617e+00</td>\n",
       "      <td>2.457146e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0             1             2             3             4  \\\n",
       "count  1.326000e+03  1.326000e+03  1.326000e+03  1.326000e+03  1.326000e+03   \n",
       "mean  -1.035002e-14 -1.160124e-15  4.947274e-15 -9.380129e-15  1.081019e-14   \n",
       "std    1.000377e+00  1.000377e+00  1.000377e+00  1.000377e+00  1.000377e+00   \n",
       "min   -2.859399e+00 -2.871520e+00 -2.971664e+00 -3.106401e+00 -3.844380e+00   \n",
       "25%   -7.107663e-01 -7.111927e-01 -6.632960e-01 -6.054958e-01 -5.922116e-01   \n",
       "50%   -5.908771e-02 -6.078163e-02 -4.406811e-02 -3.635347e-02  4.112692e-02   \n",
       "75%    7.015941e-01  6.989344e-01  6.637100e-01  6.555838e-01  6.223129e-01   \n",
       "max    2.643315e+00  2.645342e+00  2.703707e+00  2.692786e+00  2.697847e+00   \n",
       "\n",
       "                  5             6             7  \n",
       "count  1.326000e+03  1.326000e+03  1.326000e+03  \n",
       "mean   6.446996e-15  2.151455e-15 -3.248616e-15  \n",
       "std    1.000377e+00  1.000377e+00  1.000377e+00  \n",
       "min   -4.266647e+00 -3.773579e+00 -4.379782e+00  \n",
       "25%   -5.788168e-01 -5.955831e-01 -5.381132e-01  \n",
       "50%    1.544036e-01  1.633087e-02  1.742722e-01  \n",
       "75%    6.364092e-01  5.798010e-01  6.163619e-01  \n",
       "max    2.458291e+00  2.787617e+00  2.457146e+00  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df(x_train_scaled).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe, the training data is now zero mean and of unit variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val_scaled = train_scale.transform(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_ = add_constant(x_train_scaled)\n",
    "x_val_ = add_constant(x_val_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1326, 9)\n",
      "(442, 9)\n"
     ]
    }
   ],
   "source": [
    "gs(x_train_)\n",
    "gs(x_val_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 1. OLS - directly solving Normal Equations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ne_OLS(x,y):\n",
    "    \"\"\" Returns coefficients by solving normal equations directly. \"\"\"\n",
    "    \n",
    "    Nv = np.shape(x)[0]\n",
    "    R = np.dot(x.T, x)/Nv\n",
    "    C = np.dot(x.T, y)/Nv\n",
    "\n",
    "    if R.ndim < 2:\n",
    "        coef = C/R\n",
    "    else:\n",
    "        coef = np.dot(np.linalg.inv(R), C)\n",
    "        \n",
    "    return coef\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 7)\n"
     ]
    }
   ],
   "source": [
    "coef_ne = ne_OLS(x_train_, y_train)\n",
    "gs(coef_ne)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(442, 7)\n"
     ]
    }
   ],
   "source": [
    "preds_ne = get_preds(x_val_, coef_ne)\n",
    "gs(preds_ne)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04806708112056249"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_ne = calc_error(y_val, preds_ne, metric='mse')\n",
    "error_ne"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Math intuition\n",
    "- Our aim is to find the best possible coefficients (coef/ weights), from the equation: $ X \\cdot coef = y $\n",
    "- i.e to minimize: $ || X \\cdot coef - y ||^2 $\n",
    "- On further simplication, we get the Normal equations, given as: $ (X^T \\cdot X) \\cdot coef = X^T \\cdot y $\n",
    "- Thus, here we find the coefficients (or weights) as: $$ coef = (X^T \\cdot X)^{-1} \\cdot (X^T \\cdot y) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 2. OLS using QR decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qr_OLS(x,y):\n",
    "    \"\"\" This function uses QR decomposition to solve the normal equations and returns the coefficients. \"\"\"\n",
    "    \n",
    "    Nv = np.shape(x)[0]\n",
    "    Q, R = np.linalg.qr(x) #factorization of x into Q and R\n",
    "    C = np.dot(Q.T, y)\n",
    "    \n",
    "    coef = np.dot(np.linalg.inv(R), C)\n",
    "        \n",
    "    return coef, Q, R\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 7)\n"
     ]
    }
   ],
   "source": [
    "coef_qr, q, r = qr_OLS(x_train_, y_train)\n",
    "gs(coef_qr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(442, 7)\n"
     ]
    }
   ],
   "source": [
    "preds_qr = get_preds(x_val_, coef_qr)\n",
    "gs(preds_qr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04806708112046354"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_qr = calc_error(y_val, preds_qr, metric='mse')\n",
    "error_qr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Math intuition\n",
    "- QR(X) decomposes input X into Q - orthogonal matrix and R - Upper triangular matrix.\n",
    "- QR decomposition method is more stable because it avoids forming: $ X^T \\cdot X $\n",
    "- Substituting X as QR in the normal equations, we get the solution to be: $ R \\cdot coef = Q^T \\cdot y $\n",
    "- Inverse of orthogonal matrix Q is nothing but it's transpose, thus, no complex computation is required. Inverting an upper triangular matrix is faster than inverting $ X^T \\cdot X $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 3. OLS using SVD and PseudoInverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svd_OLS(x,y):\n",
    "    \"\"\" This function uses SVD decomposition and pseudoinverse to solve the normal equations and returns the coefficients.\"\"\"\n",
    "    \n",
    "    Nv = np.shape(x)[0]\n",
    "    u, s, vt = scipy.linalg.svd(x, full_matrices=False)\n",
    "    \n",
    "    s_nz = s[s>0] #Selecting the non-zero singular values \n",
    "    s_inv = np.array([1/i for i in s_nz]) # Inverting the non-zero singular values. \n",
    "    \n",
    "    m, n = len(s), len(s_inv)\n",
    "    if m != n:\n",
    "        s_inv = np.append(s_inv, np.zeros((m-n,1),float))\n",
    "        \n",
    "    s_inv_ = np.diag(s_inv) # converting 1D array to 2-D diagonal matrix\n",
    "\n",
    "    pseudo_inv = vt.T @ s_inv_ @ u.T \n",
    "\n",
    "    coef = np.dot(pseudo_inv, y)\n",
    "    \n",
    "    # One can directly use scipy or numpy's linalg.pinv(x) \n",
    "    # coef = np.dot( np.linalg.pinv(x), y)\n",
    "    \n",
    "    return coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 7)\n"
     ]
    }
   ],
   "source": [
    "coef_svd = svd_OLS(x_train_, y_train)\n",
    "gs(coef_svd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(442, 7)\n"
     ]
    }
   ],
   "source": [
    "preds_svd = get_preds(x_val_, coef_svd)\n",
    "gs(preds_svd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04806708112046273"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_svd = calc_error(y_val, preds_svd, metric='mse')\n",
    "error_svd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Math intuition\n",
    "- SVD numerically accurate and stable method, but at the same time it is a bit computationally expensive than other methods.\n",
    "- We decompose X into orthogonal matrices U and V transpose, and a diagonal matrix, S: $ X = U \\cdot S \\cdot V^T $\n",
    "- Substituting X as above in the Normal equations and further simplifying it,  gives us: \n",
    "$$ coef = (V \\cdot S^{-1} \\cdot U^T) \\cdot y  $$\n",
    "- Now, if any of the singular values of S equals 0 then S inverse doesn't exist. In such case, we perform pseudoinverse. i.e. we take reciprocal of non-zero singular values and leave all zero singular values at zero.\n",
    "- This new matrix is called as the pseudoinverse of S, denoted as:  $ S^+ $\n",
    "- And hence, in such cases we get pseudoinverse of X, as:  $ X^+ = V \\cdot S^+ \\cdot U^T $\n",
    "- Finally we can compute the weights/ coefficients as: $$ coef = X^+ \\cdot y $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Comparing with sklearn's LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(fit_intercept=False)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LinearRegression(fit_intercept=False)\n",
    "lr.fit(x_train_, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_lr = lr.predict(x_val_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.048067081120463366"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_lr = calc_error(y_val, preds_lr, metric='mse')\n",
    "error_lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "- We can see, all three methods gave approximately similar results as from Linear Regression.\n",
    "- sklearn's LR uses SVD (LAPACK's SVD), with Divide and Conquer approach.\n",
    "- Though, for the given data we got similar results, some of the data may not work well with the 1st approach of directly inverting $ X^T \\cdot X $\n",
    "- This notebook demonstrates some of the commonly used methods used for solving linear least squares problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Testing\n",
    "\n",
    "- Fitting the complete data (x) and testing on actual test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname_test = 'Twod.tst'\n",
    "N, M = 8, 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test, y_test, Nv_test = read_approximation_files(fname_test, N, M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 8)\n",
      "(1000, 7)\n"
     ]
    }
   ],
   "source": [
    "gs(x_test)\n",
    "gs(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Processing data like earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_scale = Standardize()\n",
    "x_scaled = test_scale.fit_transform(x) # x is the complete training data loaded at the beginning of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1768, 8)\n",
      "(1768, 7)\n"
     ]
    }
   ],
   "source": [
    "gs(x)\n",
    "gs(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_scaled = test_scale.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ = add_constant(x_scaled)\n",
    "x_test_ = add_constant(x_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OLS - SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 7)\n"
     ]
    }
   ],
   "source": [
    "coef_svd_all = svd_OLS(x_, y)\n",
    "gs(coef_svd_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 7)\n"
     ]
    }
   ],
   "source": [
    "preds_svd_test = get_preds(x_test_, coef_svd_all)\n",
    "gs(preds_svd_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04987707320312501"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_svd_test = calc_error(y_test, preds_svd_test, metric='mse')\n",
    "error_svd_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sklearn's Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(fit_intercept=False)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_x = LinearRegression(fit_intercept=False)\n",
    "lr_x.fit(x_, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_lr_test = lr_x.predict(x_test_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04987707320312508"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_lr_test = calc_error(y_test, preds_lr_test, metric='mse')\n",
    "error_lr_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence, we obtained approximately equal test results using OLS-SVD and sklearn's linear regression on completely unknown test data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
